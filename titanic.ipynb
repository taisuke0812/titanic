{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/taisuke0812/titanic/blob/master/titanic.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Rj9SBzz1rFod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1161
        },
        "outputId": "6b1fabdc-3637-4123-8414-564c31c791dc"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512,input_dim = 7,activation = \"sigmoid\"))\n",
        "model.add(Dense(1024,activation = \"sigmoid\"))\n",
        "\n",
        "model.add(Dense(256,activation = \"sigmoid\"))\n",
        "model.add(Dense(128,activation = \"sigmoid\"))\n",
        "model.add(Dense(64,activation = \"sigmoid\"))\n",
        "model.add(Dense(32,activation = \"sigmoid\"))\n",
        "model.add(Dense(16,activation = \"sigmoid\"))\n",
        "model.add(Dense(8,activation = \"sigmoid\"))\n",
        "model.add(Dense(4,activation = \"sigmoid\"))\n",
        "model.add(Dense(2,activation = \"sigmoid\"))\n",
        "model.add(Dense(1,activation = \"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=30, batch_size=15)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "891/891 [==============================] - 3s 3ms/step - loss: 0.6665 - acc: 0.6162\n",
            "Epoch 2/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6662 - acc: 0.6162\n",
            "Epoch 3/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6661 - acc: 0.6162\n",
            "Epoch 4/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6658 - acc: 0.6162\n",
            "Epoch 5/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6649 - acc: 0.6162\n",
            "Epoch 6/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6629 - acc: 0.6162\n",
            "Epoch 7/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6612 - acc: 0.6162\n",
            "Epoch 8/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6625 - acc: 0.6162\n",
            "Epoch 9/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6563 - acc: 0.6162\n",
            "Epoch 10/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6532 - acc: 0.6162\n",
            "Epoch 11/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6502 - acc: 0.6162\n",
            "Epoch 12/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6539 - acc: 0.6162\n",
            "Epoch 13/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6492 - acc: 0.6162\n",
            "Epoch 14/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6466 - acc: 0.6162\n",
            "Epoch 15/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6460 - acc: 0.6162\n",
            "Epoch 16/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6439 - acc: 0.6162\n",
            "Epoch 17/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6421 - acc: 0.6162\n",
            "Epoch 18/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6408 - acc: 0.6162\n",
            "Epoch 19/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6394 - acc: 0.6162\n",
            "Epoch 20/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6381 - acc: 0.6162\n",
            "Epoch 21/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6371 - acc: 0.6532\n",
            "Epoch 22/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6359 - acc: 0.6801\n",
            "Epoch 23/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6353 - acc: 0.6801\n",
            "Epoch 24/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6342 - acc: 0.6801\n",
            "Epoch 25/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6333 - acc: 0.6801\n",
            "Epoch 26/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6328 - acc: 0.6801\n",
            "Epoch 27/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6319 - acc: 0.6801\n",
            "Epoch 28/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6313 - acc: 0.6801\n",
            "Epoch 29/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6309 - acc: 0.6801\n",
            "Epoch 30/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6303 - acc: 0.6801\n",
            "891/891 [==============================] - 0s 527us/step\n",
            "acc: 68.01%\n",
            "37.059467792510986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6KOVij9mu_r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psXfWz4liC54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7145
        },
        "outputId": "1de6d086-307d-4967-990a-70917b1677df"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(600,input_dim = 7,activation = \"sigmoid\"))\n",
        "model.add(Dense(256,activation = \"sigmoid\"))\n",
        "model.add(Dense(2,activation = \"sigmoid\"))\n",
        "model.add(Dense(10,activation = \"softmax\"))\n",
        "model.add(Dense(1,activation = \"sigmoid\"))#\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=200, batch_size=10)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "891/891 [==============================] - 2s 3ms/step - loss: 0.6844 - acc: 0.6117\n",
            "Epoch 2/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.6762 - acc: 0.6162\n",
            "Epoch 3/200\n",
            "891/891 [==============================] - 0s 528us/step - loss: 0.6697 - acc: 0.6162\n",
            "Epoch 4/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.6644 - acc: 0.6162\n",
            "Epoch 5/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.6545 - acc: 0.6162\n",
            "Epoch 6/200\n",
            "891/891 [==============================] - 0s 538us/step - loss: 0.6492 - acc: 0.6162\n",
            "Epoch 7/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.6426 - acc: 0.6162\n",
            "Epoch 8/200\n",
            "891/891 [==============================] - 0s 522us/step - loss: 0.6365 - acc: 0.6162\n",
            "Epoch 9/200\n",
            "891/891 [==============================] - 0s 519us/step - loss: 0.6307 - acc: 0.6162\n",
            "Epoch 10/200\n",
            "891/891 [==============================] - 0s 557us/step - loss: 0.6293 - acc: 0.6487\n",
            "Epoch 11/200\n",
            "891/891 [==============================] - 0s 526us/step - loss: 0.6221 - acc: 0.6981\n",
            "Epoch 12/200\n",
            "891/891 [==============================] - 0s 508us/step - loss: 0.6194 - acc: 0.6925\n",
            "Epoch 13/200\n",
            "891/891 [==============================] - 0s 537us/step - loss: 0.6008 - acc: 0.7104\n",
            "Epoch 14/200\n",
            "891/891 [==============================] - 0s 556us/step - loss: 0.5956 - acc: 0.7160\n",
            "Epoch 15/200\n",
            "891/891 [==============================] - 0s 557us/step - loss: 0.5825 - acc: 0.7262\n",
            "Epoch 16/200\n",
            "891/891 [==============================] - 0s 508us/step - loss: 0.5708 - acc: 0.7407\n",
            "Epoch 17/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.5740 - acc: 0.7385\n",
            "Epoch 18/200\n",
            "891/891 [==============================] - 0s 499us/step - loss: 0.5582 - acc: 0.7475\n",
            "Epoch 19/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.5478 - acc: 0.7576\n",
            "Epoch 20/200\n",
            "891/891 [==============================] - 0s 513us/step - loss: 0.5439 - acc: 0.7621\n",
            "Epoch 21/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.5518 - acc: 0.7643\n",
            "Epoch 22/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.5487 - acc: 0.7621\n",
            "Epoch 23/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.5168 - acc: 0.7901\n",
            "Epoch 24/200\n",
            "891/891 [==============================] - 0s 492us/step - loss: 0.5165 - acc: 0.7823\n",
            "Epoch 25/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.5047 - acc: 0.7912\n",
            "Epoch 26/200\n",
            "891/891 [==============================] - 0s 516us/step - loss: 0.4944 - acc: 0.8025\n",
            "Epoch 27/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.4899 - acc: 0.8013\n",
            "Epoch 28/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.4955 - acc: 0.7890\n",
            "Epoch 29/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.4946 - acc: 0.7946\n",
            "Epoch 30/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.4817 - acc: 0.8013\n",
            "Epoch 31/200\n",
            "891/891 [==============================] - 0s 489us/step - loss: 0.4782 - acc: 0.8070\n",
            "Epoch 32/200\n",
            "891/891 [==============================] - 0s 534us/step - loss: 0.4722 - acc: 0.8103\n",
            "Epoch 33/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.4742 - acc: 0.8025\n",
            "Epoch 34/200\n",
            "891/891 [==============================] - 0s 523us/step - loss: 0.4744 - acc: 0.8025\n",
            "Epoch 35/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.4619 - acc: 0.8103\n",
            "Epoch 36/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.4687 - acc: 0.8070\n",
            "Epoch 37/200\n",
            "891/891 [==============================] - 0s 491us/step - loss: 0.4675 - acc: 0.8002\n",
            "Epoch 38/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.4615 - acc: 0.8103\n",
            "Epoch 39/200\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.4692 - acc: 0.8103\n",
            "Epoch 40/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.4602 - acc: 0.8058\n",
            "Epoch 41/200\n",
            "891/891 [==============================] - 0s 499us/step - loss: 0.4573 - acc: 0.8081\n",
            "Epoch 42/200\n",
            "891/891 [==============================] - 0s 516us/step - loss: 0.4481 - acc: 0.8058\n",
            "Epoch 43/200\n",
            "891/891 [==============================] - 1s 567us/step - loss: 0.4494 - acc: 0.8114\n",
            "Epoch 44/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.4502 - acc: 0.8148\n",
            "Epoch 45/200\n",
            "891/891 [==============================] - 0s 521us/step - loss: 0.4413 - acc: 0.8159\n",
            "Epoch 46/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.4386 - acc: 0.8126\n",
            "Epoch 47/200\n",
            "891/891 [==============================] - 1s 563us/step - loss: 0.4497 - acc: 0.8081\n",
            "Epoch 48/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.4394 - acc: 0.8171\n",
            "Epoch 49/200\n",
            "891/891 [==============================] - 0s 501us/step - loss: 0.4420 - acc: 0.8025\n",
            "Epoch 50/200\n",
            "891/891 [==============================] - 0s 506us/step - loss: 0.4338 - acc: 0.8148\n",
            "Epoch 51/200\n",
            "891/891 [==============================] - 0s 526us/step - loss: 0.4325 - acc: 0.8171\n",
            "Epoch 52/200\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.4361 - acc: 0.8137\n",
            "Epoch 53/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.4522 - acc: 0.8126\n",
            "Epoch 54/200\n",
            "891/891 [==============================] - 0s 528us/step - loss: 0.4312 - acc: 0.8193\n",
            "Epoch 55/200\n",
            "891/891 [==============================] - 0s 526us/step - loss: 0.4354 - acc: 0.8204\n",
            "Epoch 56/200\n",
            "891/891 [==============================] - 0s 526us/step - loss: 0.4296 - acc: 0.8215\n",
            "Epoch 57/200\n",
            "891/891 [==============================] - 0s 490us/step - loss: 0.4263 - acc: 0.8238\n",
            "Epoch 58/200\n",
            "891/891 [==============================] - 0s 522us/step - loss: 0.4282 - acc: 0.8182\n",
            "Epoch 59/200\n",
            "891/891 [==============================] - 0s 506us/step - loss: 0.4244 - acc: 0.8238\n",
            "Epoch 60/200\n",
            "891/891 [==============================] - 0s 541us/step - loss: 0.4170 - acc: 0.8305\n",
            "Epoch 61/200\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.4154 - acc: 0.8227\n",
            "Epoch 62/200\n",
            "891/891 [==============================] - 0s 490us/step - loss: 0.4181 - acc: 0.8260\n",
            "Epoch 63/200\n",
            "891/891 [==============================] - 0s 522us/step - loss: 0.4198 - acc: 0.8215\n",
            "Epoch 64/200\n",
            "891/891 [==============================] - 0s 550us/step - loss: 0.4190 - acc: 0.8204\n",
            "Epoch 65/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.4128 - acc: 0.8249\n",
            "Epoch 66/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.4229 - acc: 0.8260\n",
            "Epoch 67/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.4108 - acc: 0.8272\n",
            "Epoch 68/200\n",
            "891/891 [==============================] - 0s 531us/step - loss: 0.4082 - acc: 0.8305\n",
            "Epoch 69/200\n",
            "891/891 [==============================] - 0s 541us/step - loss: 0.4081 - acc: 0.8316\n",
            "Epoch 70/200\n",
            "891/891 [==============================] - 0s 535us/step - loss: 0.4161 - acc: 0.8227\n",
            "Epoch 71/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.4097 - acc: 0.8328\n",
            "Epoch 72/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.4061 - acc: 0.8339\n",
            "Epoch 73/200\n",
            "891/891 [==============================] - 0s 560us/step - loss: 0.4164 - acc: 0.8215\n",
            "Epoch 74/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.4037 - acc: 0.8350\n",
            "Epoch 75/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.4046 - acc: 0.8339\n",
            "Epoch 76/200\n",
            "891/891 [==============================] - 0s 520us/step - loss: 0.4054 - acc: 0.8260\n",
            "Epoch 77/200\n",
            "891/891 [==============================] - 0s 520us/step - loss: 0.4008 - acc: 0.8305\n",
            "Epoch 78/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.3972 - acc: 0.8316\n",
            "Epoch 79/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.4104 - acc: 0.8204\n",
            "Epoch 80/200\n",
            "891/891 [==============================] - 0s 527us/step - loss: 0.4095 - acc: 0.8182\n",
            "Epoch 81/200\n",
            "891/891 [==============================] - 0s 558us/step - loss: 0.4022 - acc: 0.8316\n",
            "Epoch 82/200\n",
            "891/891 [==============================] - 0s 539us/step - loss: 0.4024 - acc: 0.8373\n",
            "Epoch 83/200\n",
            "891/891 [==============================] - 1s 582us/step - loss: 0.4009 - acc: 0.8227\n",
            "Epoch 84/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.3959 - acc: 0.8350\n",
            "Epoch 85/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3955 - acc: 0.8406\n",
            "Epoch 86/200\n",
            "891/891 [==============================] - 0s 531us/step - loss: 0.3923 - acc: 0.8429\n",
            "Epoch 87/200\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.3922 - acc: 0.8373\n",
            "Epoch 88/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3930 - acc: 0.8361\n",
            "Epoch 89/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.3959 - acc: 0.8328\n",
            "Epoch 90/200\n",
            "891/891 [==============================] - 0s 513us/step - loss: 0.3923 - acc: 0.8384\n",
            "Epoch 91/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3879 - acc: 0.8418\n",
            "Epoch 92/200\n",
            "891/891 [==============================] - 0s 501us/step - loss: 0.3960 - acc: 0.8294\n",
            "Epoch 93/200\n",
            "891/891 [==============================] - 0s 458us/step - loss: 0.3907 - acc: 0.8339\n",
            "Epoch 94/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.3879 - acc: 0.8339\n",
            "Epoch 95/200\n",
            "891/891 [==============================] - 0s 534us/step - loss: 0.3829 - acc: 0.8429\n",
            "Epoch 96/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3851 - acc: 0.8384\n",
            "Epoch 97/200\n",
            "891/891 [==============================] - 0s 505us/step - loss: 0.3879 - acc: 0.8373\n",
            "Epoch 98/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3814 - acc: 0.8395\n",
            "Epoch 99/200\n",
            "891/891 [==============================] - 0s 506us/step - loss: 0.3857 - acc: 0.8339\n",
            "Epoch 100/200\n",
            "891/891 [==============================] - 0s 516us/step - loss: 0.3849 - acc: 0.8384\n",
            "Epoch 101/200\n",
            "891/891 [==============================] - 0s 506us/step - loss: 0.3882 - acc: 0.8373\n",
            "Epoch 102/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3841 - acc: 0.8395\n",
            "Epoch 103/200\n",
            "891/891 [==============================] - 0s 504us/step - loss: 0.3782 - acc: 0.8418\n",
            "Epoch 104/200\n",
            "891/891 [==============================] - 0s 502us/step - loss: 0.4035 - acc: 0.8294\n",
            "Epoch 105/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.4136 - acc: 0.8215\n",
            "Epoch 106/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3806 - acc: 0.8395\n",
            "Epoch 107/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.3753 - acc: 0.8418\n",
            "Epoch 108/200\n",
            "891/891 [==============================] - 0s 559us/step - loss: 0.3807 - acc: 0.8373\n",
            "Epoch 109/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.3845 - acc: 0.8406\n",
            "Epoch 110/200\n",
            "891/891 [==============================] - 0s 516us/step - loss: 0.3725 - acc: 0.8451\n",
            "Epoch 111/200\n",
            "891/891 [==============================] - 0s 513us/step - loss: 0.3845 - acc: 0.8361\n",
            "Epoch 112/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3798 - acc: 0.8384\n",
            "Epoch 113/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3743 - acc: 0.8429\n",
            "Epoch 114/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3741 - acc: 0.8496\n",
            "Epoch 115/200\n",
            "891/891 [==============================] - 0s 522us/step - loss: 0.3840 - acc: 0.8361\n",
            "Epoch 116/200\n",
            "891/891 [==============================] - 0s 546us/step - loss: 0.3761 - acc: 0.8373\n",
            "Epoch 117/200\n",
            "891/891 [==============================] - 0s 505us/step - loss: 0.3853 - acc: 0.8361\n",
            "Epoch 118/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3709 - acc: 0.8462\n",
            "Epoch 119/200\n",
            "891/891 [==============================] - 0s 534us/step - loss: 0.3732 - acc: 0.8395\n",
            "Epoch 120/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.3765 - acc: 0.8384\n",
            "Epoch 121/200\n",
            "891/891 [==============================] - 0s 529us/step - loss: 0.3730 - acc: 0.8474\n",
            "Epoch 122/200\n",
            "891/891 [==============================] - 0s 528us/step - loss: 0.3715 - acc: 0.8406\n",
            "Epoch 123/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.3715 - acc: 0.8451\n",
            "Epoch 124/200\n",
            "891/891 [==============================] - 0s 549us/step - loss: 0.3646 - acc: 0.8519\n",
            "Epoch 125/200\n",
            "891/891 [==============================] - 0s 560us/step - loss: 0.3676 - acc: 0.8418\n",
            "Epoch 126/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.3656 - acc: 0.8451\n",
            "Epoch 127/200\n",
            "891/891 [==============================] - 0s 529us/step - loss: 0.3747 - acc: 0.8361\n",
            "Epoch 128/200\n",
            "891/891 [==============================] - 0s 552us/step - loss: 0.3731 - acc: 0.8440\n",
            "Epoch 129/200\n",
            "891/891 [==============================] - 1s 571us/step - loss: 0.3679 - acc: 0.8418\n",
            "Epoch 130/200\n",
            "891/891 [==============================] - 0s 541us/step - loss: 0.3699 - acc: 0.8507\n",
            "Epoch 131/200\n",
            "891/891 [==============================] - 0s 533us/step - loss: 0.3767 - acc: 0.8406\n",
            "Epoch 132/200\n",
            "891/891 [==============================] - 0s 540us/step - loss: 0.3721 - acc: 0.8474\n",
            "Epoch 133/200\n",
            "891/891 [==============================] - 0s 550us/step - loss: 0.3736 - acc: 0.8507\n",
            "Epoch 134/200\n",
            "891/891 [==============================] - 0s 494us/step - loss: 0.3698 - acc: 0.8462\n",
            "Epoch 135/200\n",
            "891/891 [==============================] - 0s 533us/step - loss: 0.3718 - acc: 0.8462\n",
            "Epoch 136/200\n",
            "891/891 [==============================] - 0s 548us/step - loss: 0.3667 - acc: 0.8507\n",
            "Epoch 137/200\n",
            "891/891 [==============================] - 0s 520us/step - loss: 0.3622 - acc: 0.8530\n",
            "Epoch 138/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.3691 - acc: 0.8496\n",
            "Epoch 139/200\n",
            "891/891 [==============================] - 0s 558us/step - loss: 0.3636 - acc: 0.8474\n",
            "Epoch 140/200\n",
            "891/891 [==============================] - 0s 528us/step - loss: 0.3790 - acc: 0.8384\n",
            "Epoch 141/200\n",
            "891/891 [==============================] - 0s 533us/step - loss: 0.3666 - acc: 0.8451\n",
            "Epoch 142/200\n",
            "891/891 [==============================] - 1s 566us/step - loss: 0.3804 - acc: 0.8305\n",
            "Epoch 143/200\n",
            "891/891 [==============================] - 0s 555us/step - loss: 0.3669 - acc: 0.8395\n",
            "Epoch 144/200\n",
            "891/891 [==============================] - 0s 522us/step - loss: 0.3658 - acc: 0.8485\n",
            "Epoch 145/200\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.3657 - acc: 0.8507\n",
            "Epoch 146/200\n",
            "891/891 [==============================] - 0s 530us/step - loss: 0.3601 - acc: 0.8507\n",
            "Epoch 147/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.3716 - acc: 0.8440\n",
            "Epoch 148/200\n",
            "891/891 [==============================] - 0s 531us/step - loss: 0.3645 - acc: 0.8462\n",
            "Epoch 149/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.3695 - acc: 0.8429\n",
            "Epoch 150/200\n",
            "891/891 [==============================] - 0s 538us/step - loss: 0.3651 - acc: 0.8485\n",
            "Epoch 151/200\n",
            "891/891 [==============================] - 0s 542us/step - loss: 0.3711 - acc: 0.8462\n",
            "Epoch 152/200\n",
            "891/891 [==============================] - 0s 539us/step - loss: 0.3641 - acc: 0.8474\n",
            "Epoch 153/200\n",
            "891/891 [==============================] - 0s 524us/step - loss: 0.3714 - acc: 0.8384\n",
            "Epoch 154/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3642 - acc: 0.8519\n",
            "Epoch 155/200\n",
            "891/891 [==============================] - 0s 519us/step - loss: 0.3572 - acc: 0.8563\n",
            "Epoch 156/200\n",
            "891/891 [==============================] - 0s 477us/step - loss: 0.3563 - acc: 0.8530\n",
            "Epoch 157/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.3623 - acc: 0.8507\n",
            "Epoch 158/200\n",
            "891/891 [==============================] - 0s 508us/step - loss: 0.3642 - acc: 0.8451\n",
            "Epoch 159/200\n",
            "891/891 [==============================] - 0s 540us/step - loss: 0.3669 - acc: 0.8496\n",
            "Epoch 160/200\n",
            "891/891 [==============================] - 0s 524us/step - loss: 0.3563 - acc: 0.8507\n",
            "Epoch 161/200\n",
            "891/891 [==============================] - 0s 523us/step - loss: 0.3544 - acc: 0.8608\n",
            "Epoch 162/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.3670 - acc: 0.8418\n",
            "Epoch 163/200\n",
            "891/891 [==============================] - 0s 519us/step - loss: 0.3593 - acc: 0.8552\n",
            "Epoch 164/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.3560 - acc: 0.8597\n",
            "Epoch 165/200\n",
            "891/891 [==============================] - 0s 524us/step - loss: 0.3540 - acc: 0.8552\n",
            "Epoch 166/200\n",
            "891/891 [==============================] - 0s 521us/step - loss: 0.3522 - acc: 0.8597\n",
            "Epoch 167/200\n",
            "891/891 [==============================] - 0s 523us/step - loss: 0.3522 - acc: 0.8575\n",
            "Epoch 168/200\n",
            "891/891 [==============================] - 0s 551us/step - loss: 0.3562 - acc: 0.8563\n",
            "Epoch 169/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3510 - acc: 0.8541\n",
            "Epoch 170/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3539 - acc: 0.8597\n",
            "Epoch 171/200\n",
            "891/891 [==============================] - 0s 489us/step - loss: 0.3642 - acc: 0.8519\n",
            "Epoch 172/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3601 - acc: 0.8541\n",
            "Epoch 173/200\n",
            "891/891 [==============================] - 0s 523us/step - loss: 0.3506 - acc: 0.8575\n",
            "Epoch 174/200\n",
            "891/891 [==============================] - 0s 530us/step - loss: 0.3569 - acc: 0.8586\n",
            "Epoch 175/200\n",
            "891/891 [==============================] - 0s 516us/step - loss: 0.3512 - acc: 0.8575\n",
            "Epoch 176/200\n",
            "891/891 [==============================] - 0s 528us/step - loss: 0.3583 - acc: 0.8485\n",
            "Epoch 177/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3585 - acc: 0.8507\n",
            "Epoch 178/200\n",
            "891/891 [==============================] - 0s 494us/step - loss: 0.3570 - acc: 0.8575\n",
            "Epoch 179/200\n",
            "891/891 [==============================] - 0s 501us/step - loss: 0.3574 - acc: 0.8608\n",
            "Epoch 180/200\n",
            "891/891 [==============================] - 0s 513us/step - loss: 0.3523 - acc: 0.8563\n",
            "Epoch 181/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3486 - acc: 0.8620\n",
            "Epoch 182/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.3573 - acc: 0.8541\n",
            "Epoch 183/200\n",
            "891/891 [==============================] - 0s 523us/step - loss: 0.3618 - acc: 0.8541\n",
            "Epoch 184/200\n",
            "891/891 [==============================] - 0s 545us/step - loss: 0.3506 - acc: 0.8586\n",
            "Epoch 185/200\n",
            "891/891 [==============================] - 0s 537us/step - loss: 0.3459 - acc: 0.8642\n",
            "Epoch 186/200\n",
            "891/891 [==============================] - 0s 519us/step - loss: 0.3454 - acc: 0.8575\n",
            "Epoch 187/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.3449 - acc: 0.8664\n",
            "Epoch 188/200\n",
            "891/891 [==============================] - 0s 543us/step - loss: 0.3489 - acc: 0.8586\n",
            "Epoch 189/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.3447 - acc: 0.8552\n",
            "Epoch 190/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.3495 - acc: 0.8608\n",
            "Epoch 191/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.3817 - acc: 0.8485\n",
            "Epoch 192/200\n",
            "891/891 [==============================] - 0s 557us/step - loss: 0.3484 - acc: 0.8575\n",
            "Epoch 193/200\n",
            "891/891 [==============================] - 0s 531us/step - loss: 0.3509 - acc: 0.8620\n",
            "Epoch 194/200\n",
            "891/891 [==============================] - 0s 527us/step - loss: 0.3483 - acc: 0.8620\n",
            "Epoch 195/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.3397 - acc: 0.8698\n",
            "Epoch 196/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.3473 - acc: 0.8687\n",
            "Epoch 197/200\n",
            "891/891 [==============================] - 0s 537us/step - loss: 0.3467 - acc: 0.8620\n",
            "Epoch 198/200\n",
            "891/891 [==============================] - 0s 554us/step - loss: 0.3516 - acc: 0.8563\n",
            "Epoch 199/200\n",
            "891/891 [==============================] - 0s 524us/step - loss: 0.3631 - acc: 0.8530\n",
            "Epoch 200/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.3588 - acc: 0.8541\n",
            "891/891 [==============================] - 1s 870us/step\n",
            "acc: 85.75%\n",
            "97.17915868759155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yOdR9ObTzEmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1161
        },
        "outputId": "5aaa5c65-6738-457f-9e7d-0221104823eb"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512,input_dim = 7,activation = \"sigmoid\"))\n",
        "model.add(Dense(300,activation = \"sigmoid\"))\n",
        "model.add(Dense(1,activation = \"sigmoid\"))#\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=30, batch_size=10)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6347 - acc: 0.6510\n",
            "Epoch 2/30\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.6123 - acc: 0.6824\n",
            "Epoch 3/30\n",
            "891/891 [==============================] - 1s 605us/step - loss: 0.6077 - acc: 0.6925\n",
            "Epoch 4/30\n",
            "891/891 [==============================] - 0s 459us/step - loss: 0.5669 - acc: 0.7194\n",
            "Epoch 5/30\n",
            "891/891 [==============================] - 0s 447us/step - loss: 0.5201 - acc: 0.7699\n",
            "Epoch 6/30\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.5124 - acc: 0.7722\n",
            "Epoch 7/30\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4910 - acc: 0.7688\n",
            "Epoch 8/30\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4821 - acc: 0.7699\n",
            "Epoch 9/30\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4690 - acc: 0.7957\n",
            "Epoch 10/30\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4586 - acc: 0.7699\n",
            "Epoch 11/30\n",
            "891/891 [==============================] - 0s 438us/step - loss: 0.4480 - acc: 0.7957\n",
            "Epoch 12/30\n",
            "891/891 [==============================] - 0s 458us/step - loss: 0.4512 - acc: 0.7957\n",
            "Epoch 13/30\n",
            "891/891 [==============================] - 0s 439us/step - loss: 0.4610 - acc: 0.7957\n",
            "Epoch 14/30\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.4485 - acc: 0.7980\n",
            "Epoch 15/30\n",
            "891/891 [==============================] - 0s 433us/step - loss: 0.4622 - acc: 0.7823\n",
            "Epoch 16/30\n",
            "891/891 [==============================] - 0s 441us/step - loss: 0.4471 - acc: 0.7980\n",
            "Epoch 17/30\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.4388 - acc: 0.7935\n",
            "Epoch 18/30\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.4478 - acc: 0.7946\n",
            "Epoch 19/30\n",
            "891/891 [==============================] - 0s 461us/step - loss: 0.4481 - acc: 0.7969\n",
            "Epoch 20/30\n",
            "891/891 [==============================] - 0s 426us/step - loss: 0.4358 - acc: 0.8002\n",
            "Epoch 21/30\n",
            "891/891 [==============================] - 0s 454us/step - loss: 0.4395 - acc: 0.8070\n",
            "Epoch 22/30\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4340 - acc: 0.8036\n",
            "Epoch 23/30\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.4525 - acc: 0.8058\n",
            "Epoch 24/30\n",
            "891/891 [==============================] - 0s 435us/step - loss: 0.4313 - acc: 0.8036\n",
            "Epoch 25/30\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4422 - acc: 0.8126\n",
            "Epoch 26/30\n",
            "891/891 [==============================] - 0s 465us/step - loss: 0.4308 - acc: 0.8171\n",
            "Epoch 27/30\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4296 - acc: 0.8058\n",
            "Epoch 28/30\n",
            "891/891 [==============================] - 0s 448us/step - loss: 0.4182 - acc: 0.8148\n",
            "Epoch 29/30\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.4349 - acc: 0.8058\n",
            "Epoch 30/30\n",
            "891/891 [==============================] - 0s 450us/step - loss: 0.4224 - acc: 0.8058\n",
            "891/891 [==============================] - 0s 308us/step\n",
            "acc: 79.80%\n",
            "14.150184154510498\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}