{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/taisuke0812/titanic/blob/master/titanic.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Rj9SBzz1rFod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1161
        },
        "outputId": "4da1bdfb-fc3b-4f7d-8b93-91137b91d318"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Dropout\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512,input_dim = 7,activation = \"sigmoid\"))\n",
        "model.add(Dense(1024,activation = \"sigmoid\"))\n",
        "\n",
        "model.add(Dense(256,activation = \"sigmoid\"))\n",
        "model.add(Dense(128,activation = \"sigmoid\"))\n",
        "model.add(Dense(64,activation = \"sigmoid\"))\n",
        "model.add(Dense(32,activation = \"sigmoid\"))\n",
        "model.add(Dense(16,activation = \"sigmoid\"))\n",
        "model.add(Dense(8,activation = \"sigmoid\"))\n",
        "model.add(Dense(4,activation = \"sigmoid\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2,activation = \"sigmoid\"))\n",
        "model.add(Dense(1,activation = \"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=30, batch_size=15)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "891/891 [==============================] - 3s 4ms/step - loss: 0.6706 - acc: 0.6162\n",
            "Epoch 2/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6684 - acc: 0.6162\n",
            "Epoch 3/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6668 - acc: 0.6162\n",
            "Epoch 4/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6670 - acc: 0.6162\n",
            "Epoch 5/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6669 - acc: 0.6162\n",
            "Epoch 6/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6661 - acc: 0.6162\n",
            "Epoch 7/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6666 - acc: 0.6162\n",
            "Epoch 8/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6662 - acc: 0.6162\n",
            "Epoch 9/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6660 - acc: 0.6162\n",
            "Epoch 10/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6666 - acc: 0.6162\n",
            "Epoch 11/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6667 - acc: 0.6162\n",
            "Epoch 12/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6661 - acc: 0.6162\n",
            "Epoch 13/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6664 - acc: 0.6162\n",
            "Epoch 14/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6663 - acc: 0.6162\n",
            "Epoch 15/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6661 - acc: 0.6162\n",
            "Epoch 16/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6661 - acc: 0.6162\n",
            "Epoch 17/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6663 - acc: 0.6162\n",
            "Epoch 18/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6658 - acc: 0.6162\n",
            "Epoch 19/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6659 - acc: 0.6162\n",
            "Epoch 20/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6662 - acc: 0.6162\n",
            "Epoch 21/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6658 - acc: 0.6162\n",
            "Epoch 22/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6661 - acc: 0.6162\n",
            "Epoch 23/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6662 - acc: 0.6162\n",
            "Epoch 24/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6664 - acc: 0.6162\n",
            "Epoch 25/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6662 - acc: 0.6162\n",
            "Epoch 26/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6662 - acc: 0.6162\n",
            "Epoch 27/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6660 - acc: 0.6162\n",
            "Epoch 28/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6655 - acc: 0.6162\n",
            "Epoch 29/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6656 - acc: 0.6162\n",
            "Epoch 30/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6660 - acc: 0.6162\n",
            "891/891 [==============================] - 1s 1ms/step\n",
            "acc: 61.62%\n",
            "36.38410210609436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6KOVij9mu_r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psXfWz4liC54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4329
        },
        "outputId": "a7d22268-0183-4795-d3a5-123d9c255ff0"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Dropout\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "#今のところベスト\n",
        "\n",
        "model.add(Dense(600,input_dim = 7,activation = \"sigmoid\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(256,activation = \"sigmoid\"))\n",
        "model.add(Dense(2,activation = \"sigmoid\"))\n",
        "model.add(Dense(10,activation = \"sigmoid\"))\n",
        "model.add(Dense(3,activation = \"softmax\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation = \"sigmoid\"))#\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=120, batch_size=10)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "891/891 [==============================] - 4s 4ms/step - loss: 0.6786 - acc: 0.6094\n",
            "Epoch 2/120\n",
            "891/891 [==============================] - 1s 614us/step - loss: 0.6719 - acc: 0.6128\n",
            "Epoch 3/120\n",
            "891/891 [==============================] - 1s 595us/step - loss: 0.6699 - acc: 0.6094\n",
            "Epoch 4/120\n",
            "891/891 [==============================] - 1s 613us/step - loss: 0.6702 - acc: 0.6139\n",
            "Epoch 5/120\n",
            "891/891 [==============================] - 1s 576us/step - loss: 0.6640 - acc: 0.6173\n",
            "Epoch 6/120\n",
            "891/891 [==============================] - 1s 601us/step - loss: 0.6687 - acc: 0.6173\n",
            "Epoch 7/120\n",
            "891/891 [==============================] - 1s 634us/step - loss: 0.6664 - acc: 0.6162\n",
            "Epoch 8/120\n",
            "891/891 [==============================] - 1s 604us/step - loss: 0.6584 - acc: 0.6162\n",
            "Epoch 9/120\n",
            "891/891 [==============================] - 1s 648us/step - loss: 0.6536 - acc: 0.6139\n",
            "Epoch 10/120\n",
            "891/891 [==============================] - 1s 646us/step - loss: 0.6597 - acc: 0.6072\n",
            "Epoch 11/120\n",
            "891/891 [==============================] - 1s 632us/step - loss: 0.6533 - acc: 0.6139\n",
            "Epoch 12/120\n",
            "891/891 [==============================] - 1s 569us/step - loss: 0.6592 - acc: 0.6117\n",
            "Epoch 13/120\n",
            "891/891 [==============================] - 1s 582us/step - loss: 0.6455 - acc: 0.6061\n",
            "Epoch 14/120\n",
            "891/891 [==============================] - 1s 592us/step - loss: 0.6474 - acc: 0.6004\n",
            "Epoch 15/120\n",
            "891/891 [==============================] - 1s 642us/step - loss: 0.6361 - acc: 0.6105\n",
            "Epoch 16/120\n",
            "891/891 [==============================] - 1s 598us/step - loss: 0.6483 - acc: 0.5915\n",
            "Epoch 17/120\n",
            "891/891 [==============================] - 1s 635us/step - loss: 0.6376 - acc: 0.5746\n",
            "Epoch 18/120\n",
            "891/891 [==============================] - 1s 636us/step - loss: 0.6266 - acc: 0.5814\n",
            "Epoch 19/120\n",
            "891/891 [==============================] - 1s 676us/step - loss: 0.6183 - acc: 0.5825\n",
            "Epoch 20/120\n",
            "891/891 [==============================] - 1s 620us/step - loss: 0.6226 - acc: 0.5477\n",
            "Epoch 21/120\n",
            "891/891 [==============================] - 1s 663us/step - loss: 0.6009 - acc: 0.5836\n",
            "Epoch 22/120\n",
            "891/891 [==============================] - 1s 658us/step - loss: 0.6135 - acc: 0.5410\n",
            "Epoch 23/120\n",
            "891/891 [==============================] - 1s 648us/step - loss: 0.5925 - acc: 0.6296\n",
            "Epoch 24/120\n",
            "891/891 [==============================] - 1s 596us/step - loss: 0.5859 - acc: 0.6409\n",
            "Epoch 25/120\n",
            "891/891 [==============================] - 1s 583us/step - loss: 0.5850 - acc: 0.6723\n",
            "Epoch 26/120\n",
            "891/891 [==============================] - 1s 614us/step - loss: 0.5650 - acc: 0.6745\n",
            "Epoch 27/120\n",
            "891/891 [==============================] - 1s 622us/step - loss: 0.5596 - acc: 0.6768\n",
            "Epoch 28/120\n",
            "891/891 [==============================] - 1s 597us/step - loss: 0.5586 - acc: 0.6813\n",
            "Epoch 29/120\n",
            "891/891 [==============================] - 1s 646us/step - loss: 0.5699 - acc: 0.6947\n",
            "Epoch 30/120\n",
            "891/891 [==============================] - 1s 615us/step - loss: 0.5652 - acc: 0.7217\n",
            "Epoch 31/120\n",
            "891/891 [==============================] - 1s 605us/step - loss: 0.5550 - acc: 0.7183\n",
            "Epoch 32/120\n",
            "891/891 [==============================] - 1s 618us/step - loss: 0.5686 - acc: 0.7138\n",
            "Epoch 33/120\n",
            "891/891 [==============================] - 1s 643us/step - loss: 0.5525 - acc: 0.7284\n",
            "Epoch 34/120\n",
            "891/891 [==============================] - 1s 592us/step - loss: 0.5568 - acc: 0.7194\n",
            "Epoch 35/120\n",
            "891/891 [==============================] - 1s 636us/step - loss: 0.5543 - acc: 0.7273\n",
            "Epoch 36/120\n",
            "891/891 [==============================] - 1s 590us/step - loss: 0.5390 - acc: 0.7318\n",
            "Epoch 37/120\n",
            "891/891 [==============================] - 1s 623us/step - loss: 0.5330 - acc: 0.7340\n",
            "Epoch 38/120\n",
            "891/891 [==============================] - 1s 623us/step - loss: 0.5438 - acc: 0.7228\n",
            "Epoch 39/120\n",
            "891/891 [==============================] - 1s 655us/step - loss: 0.5332 - acc: 0.7385\n",
            "Epoch 40/120\n",
            "891/891 [==============================] - 1s 599us/step - loss: 0.5253 - acc: 0.7396\n",
            "Epoch 41/120\n",
            "891/891 [==============================] - 1s 581us/step - loss: 0.5178 - acc: 0.7553\n",
            "Epoch 42/120\n",
            "891/891 [==============================] - 1s 594us/step - loss: 0.5257 - acc: 0.7553\n",
            "Epoch 43/120\n",
            "891/891 [==============================] - 1s 618us/step - loss: 0.5340 - acc: 0.7262\n",
            "Epoch 44/120\n",
            "891/891 [==============================] - 1s 632us/step - loss: 0.5179 - acc: 0.7497\n",
            "Epoch 45/120\n",
            "891/891 [==============================] - 1s 593us/step - loss: 0.5097 - acc: 0.7587\n",
            "Epoch 46/120\n",
            "891/891 [==============================] - 1s 664us/step - loss: 0.5229 - acc: 0.7520\n",
            "Epoch 47/120\n",
            "891/891 [==============================] - 1s 646us/step - loss: 0.5190 - acc: 0.7374\n",
            "Epoch 48/120\n",
            "891/891 [==============================] - 1s 633us/step - loss: 0.5165 - acc: 0.7475\n",
            "Epoch 49/120\n",
            "891/891 [==============================] - 1s 629us/step - loss: 0.5183 - acc: 0.7587\n",
            "Epoch 50/120\n",
            "891/891 [==============================] - 1s 623us/step - loss: 0.5164 - acc: 0.7632\n",
            "Epoch 51/120\n",
            "891/891 [==============================] - 1s 655us/step - loss: 0.5132 - acc: 0.7475\n",
            "Epoch 52/120\n",
            "891/891 [==============================] - 1s 616us/step - loss: 0.5084 - acc: 0.7565\n",
            "Epoch 53/120\n",
            "891/891 [==============================] - 1s 641us/step - loss: 0.5131 - acc: 0.7699\n",
            "Epoch 54/120\n",
            "891/891 [==============================] - 1s 673us/step - loss: 0.5025 - acc: 0.7576\n",
            "Epoch 55/120\n",
            "891/891 [==============================] - 1s 648us/step - loss: 0.5158 - acc: 0.7475\n",
            "Epoch 56/120\n",
            "891/891 [==============================] - 1s 599us/step - loss: 0.5100 - acc: 0.7722\n",
            "Epoch 57/120\n",
            "891/891 [==============================] - 1s 587us/step - loss: 0.5061 - acc: 0.7778\n",
            "Epoch 58/120\n",
            "891/891 [==============================] - 1s 648us/step - loss: 0.5079 - acc: 0.7733\n",
            "Epoch 59/120\n",
            "891/891 [==============================] - 1s 618us/step - loss: 0.5063 - acc: 0.7419\n",
            "Epoch 60/120\n",
            "891/891 [==============================] - 1s 671us/step - loss: 0.5220 - acc: 0.7396\n",
            "Epoch 61/120\n",
            "891/891 [==============================] - 1s 674us/step - loss: 0.5000 - acc: 0.7666\n",
            "Epoch 62/120\n",
            "891/891 [==============================] - 1s 656us/step - loss: 0.4980 - acc: 0.7363\n",
            "Epoch 63/120\n",
            "891/891 [==============================] - 1s 629us/step - loss: 0.4993 - acc: 0.7643\n",
            "Epoch 64/120\n",
            "891/891 [==============================] - 1s 601us/step - loss: 0.5039 - acc: 0.7609\n",
            "Epoch 65/120\n",
            "891/891 [==============================] - 1s 623us/step - loss: 0.5196 - acc: 0.7520\n",
            "Epoch 66/120\n",
            "891/891 [==============================] - 1s 605us/step - loss: 0.5121 - acc: 0.7475\n",
            "Epoch 67/120\n",
            "891/891 [==============================] - 1s 612us/step - loss: 0.5066 - acc: 0.7688\n",
            "Epoch 68/120\n",
            "891/891 [==============================] - 1s 641us/step - loss: 0.5054 - acc: 0.7609\n",
            "Epoch 69/120\n",
            "891/891 [==============================] - 1s 630us/step - loss: 0.4957 - acc: 0.7666\n",
            "Epoch 70/120\n",
            "891/891 [==============================] - 1s 645us/step - loss: 0.4837 - acc: 0.7800\n",
            "Epoch 71/120\n",
            "891/891 [==============================] - 1s 672us/step - loss: 0.4984 - acc: 0.7677\n",
            "Epoch 72/120\n",
            "891/891 [==============================] - 1s 653us/step - loss: 0.5112 - acc: 0.7654\n",
            "Epoch 73/120\n",
            "891/891 [==============================] - 1s 663us/step - loss: 0.5024 - acc: 0.7576\n",
            "Epoch 74/120\n",
            "891/891 [==============================] - 1s 626us/step - loss: 0.4959 - acc: 0.7710\n",
            "Epoch 75/120\n",
            "891/891 [==============================] - 1s 691us/step - loss: 0.5025 - acc: 0.7621\n",
            "Epoch 76/120\n",
            "891/891 [==============================] - 1s 649us/step - loss: 0.4950 - acc: 0.7497\n",
            "Epoch 77/120\n",
            "891/891 [==============================] - 1s 600us/step - loss: 0.5027 - acc: 0.7531\n",
            "Epoch 78/120\n",
            "891/891 [==============================] - 1s 625us/step - loss: 0.4963 - acc: 0.7598\n",
            "Epoch 79/120\n",
            "891/891 [==============================] - 1s 628us/step - loss: 0.4768 - acc: 0.7856\n",
            "Epoch 80/120\n",
            "891/891 [==============================] - 1s 635us/step - loss: 0.4939 - acc: 0.7677\n",
            "Epoch 81/120\n",
            "891/891 [==============================] - 1s 596us/step - loss: 0.4897 - acc: 0.7688\n",
            "Epoch 82/120\n",
            "891/891 [==============================] - 1s 629us/step - loss: 0.4942 - acc: 0.7744\n",
            "Epoch 83/120\n",
            "891/891 [==============================] - 1s 610us/step - loss: 0.5051 - acc: 0.7666\n",
            "Epoch 84/120\n",
            "891/891 [==============================] - 1s 591us/step - loss: 0.5038 - acc: 0.7587\n",
            "Epoch 85/120\n",
            "891/891 [==============================] - 1s 652us/step - loss: 0.4800 - acc: 0.7789\n",
            "Epoch 86/120\n",
            "891/891 [==============================] - 1s 644us/step - loss: 0.4937 - acc: 0.7688\n",
            "Epoch 87/120\n",
            "891/891 [==============================] - 1s 624us/step - loss: 0.4930 - acc: 0.7587\n",
            "Epoch 88/120\n",
            "891/891 [==============================] - 1s 610us/step - loss: 0.5069 - acc: 0.7419\n",
            "Epoch 89/120\n",
            "891/891 [==============================] - 1s 616us/step - loss: 0.4894 - acc: 0.7654\n",
            "Epoch 90/120\n",
            "891/891 [==============================] - 1s 639us/step - loss: 0.4989 - acc: 0.7587\n",
            "Epoch 91/120\n",
            "891/891 [==============================] - 1s 603us/step - loss: 0.4842 - acc: 0.7699\n",
            "Epoch 92/120\n",
            "891/891 [==============================] - 1s 617us/step - loss: 0.4790 - acc: 0.7733\n",
            "Epoch 93/120\n",
            "891/891 [==============================] - 1s 589us/step - loss: 0.4754 - acc: 0.7845\n",
            "Epoch 94/120\n",
            "891/891 [==============================] - 1s 592us/step - loss: 0.4955 - acc: 0.7621\n",
            "Epoch 95/120\n",
            "891/891 [==============================] - 1s 638us/step - loss: 0.4914 - acc: 0.7710\n",
            "Epoch 96/120\n",
            "891/891 [==============================] - 1s 646us/step - loss: 0.5055 - acc: 0.7508\n",
            "Epoch 97/120\n",
            "891/891 [==============================] - 1s 681us/step - loss: 0.4895 - acc: 0.7609\n",
            "Epoch 98/120\n",
            "891/891 [==============================] - 1s 622us/step - loss: 0.4780 - acc: 0.7632\n",
            "Epoch 99/120\n",
            "891/891 [==============================] - 1s 676us/step - loss: 0.4789 - acc: 0.7666\n",
            "Epoch 100/120\n",
            "891/891 [==============================] - 1s 648us/step - loss: 0.4901 - acc: 0.7677\n",
            "Epoch 101/120\n",
            "891/891 [==============================] - 1s 636us/step - loss: 0.4761 - acc: 0.7609\n",
            "Epoch 102/120\n",
            "891/891 [==============================] - 1s 659us/step - loss: 0.4767 - acc: 0.7755\n",
            "Epoch 103/120\n",
            "891/891 [==============================] - 1s 657us/step - loss: 0.5083 - acc: 0.7576\n",
            "Epoch 104/120\n",
            "891/891 [==============================] - 1s 630us/step - loss: 0.4637 - acc: 0.7789\n",
            "Epoch 105/120\n",
            "891/891 [==============================] - 1s 609us/step - loss: 0.4628 - acc: 0.7811\n",
            "Epoch 106/120\n",
            "891/891 [==============================] - 1s 634us/step - loss: 0.4712 - acc: 0.7722\n",
            "Epoch 107/120\n",
            "891/891 [==============================] - 1s 599us/step - loss: 0.4802 - acc: 0.7811\n",
            "Epoch 108/120\n",
            "891/891 [==============================] - 1s 608us/step - loss: 0.4586 - acc: 0.7912\n",
            "Epoch 109/120\n",
            "891/891 [==============================] - 1s 627us/step - loss: 0.4661 - acc: 0.7744\n",
            "Epoch 110/120\n",
            "891/891 [==============================] - 1s 632us/step - loss: 0.4636 - acc: 0.7800\n",
            "Epoch 111/120\n",
            "891/891 [==============================] - 1s 618us/step - loss: 0.4702 - acc: 0.7845\n",
            "Epoch 112/120\n",
            "891/891 [==============================] - 1s 635us/step - loss: 0.4543 - acc: 0.7823\n",
            "Epoch 113/120\n",
            "891/891 [==============================] - 1s 628us/step - loss: 0.4677 - acc: 0.7856\n",
            "Epoch 114/120\n",
            "891/891 [==============================] - 1s 631us/step - loss: 0.4757 - acc: 0.7666\n",
            "Epoch 115/120\n",
            "891/891 [==============================] - 1s 631us/step - loss: 0.4643 - acc: 0.7789\n",
            "Epoch 116/120\n",
            "891/891 [==============================] - 1s 618us/step - loss: 0.4586 - acc: 0.7767\n",
            "Epoch 117/120\n",
            "891/891 [==============================] - 1s 586us/step - loss: 0.4589 - acc: 0.7811\n",
            "Epoch 118/120\n",
            "891/891 [==============================] - 1s 567us/step - loss: 0.4559 - acc: 0.7890\n",
            "Epoch 119/120\n",
            "891/891 [==============================] - 1s 563us/step - loss: 0.4649 - acc: 0.7767\n",
            "Epoch 120/120\n",
            "891/891 [==============================] - 1s 572us/step - loss: 0.4612 - acc: 0.7845\n",
            "891/891 [==============================] - 1s 1ms/step\n",
            "acc: 81.71%\n",
            "74.13187789916992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yOdR9ObTzEmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1161
        },
        "outputId": "5aaa5c65-6738-457f-9e7d-0221104823eb"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512,input_dim = 7,activation = \"sigmoid\"))\n",
        "model.add(Dense(300,activation = \"sigmoid\"))\n",
        "model.add(Dense(1,activation = \"sigmoid\"))#\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=30, batch_size=10)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "891/891 [==============================] - 1s 1ms/step - loss: 0.6347 - acc: 0.6510\n",
            "Epoch 2/30\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.6123 - acc: 0.6824\n",
            "Epoch 3/30\n",
            "891/891 [==============================] - 1s 605us/step - loss: 0.6077 - acc: 0.6925\n",
            "Epoch 4/30\n",
            "891/891 [==============================] - 0s 459us/step - loss: 0.5669 - acc: 0.7194\n",
            "Epoch 5/30\n",
            "891/891 [==============================] - 0s 447us/step - loss: 0.5201 - acc: 0.7699\n",
            "Epoch 6/30\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.5124 - acc: 0.7722\n",
            "Epoch 7/30\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4910 - acc: 0.7688\n",
            "Epoch 8/30\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4821 - acc: 0.7699\n",
            "Epoch 9/30\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4690 - acc: 0.7957\n",
            "Epoch 10/30\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4586 - acc: 0.7699\n",
            "Epoch 11/30\n",
            "891/891 [==============================] - 0s 438us/step - loss: 0.4480 - acc: 0.7957\n",
            "Epoch 12/30\n",
            "891/891 [==============================] - 0s 458us/step - loss: 0.4512 - acc: 0.7957\n",
            "Epoch 13/30\n",
            "891/891 [==============================] - 0s 439us/step - loss: 0.4610 - acc: 0.7957\n",
            "Epoch 14/30\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.4485 - acc: 0.7980\n",
            "Epoch 15/30\n",
            "891/891 [==============================] - 0s 433us/step - loss: 0.4622 - acc: 0.7823\n",
            "Epoch 16/30\n",
            "891/891 [==============================] - 0s 441us/step - loss: 0.4471 - acc: 0.7980\n",
            "Epoch 17/30\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.4388 - acc: 0.7935\n",
            "Epoch 18/30\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.4478 - acc: 0.7946\n",
            "Epoch 19/30\n",
            "891/891 [==============================] - 0s 461us/step - loss: 0.4481 - acc: 0.7969\n",
            "Epoch 20/30\n",
            "891/891 [==============================] - 0s 426us/step - loss: 0.4358 - acc: 0.8002\n",
            "Epoch 21/30\n",
            "891/891 [==============================] - 0s 454us/step - loss: 0.4395 - acc: 0.8070\n",
            "Epoch 22/30\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4340 - acc: 0.8036\n",
            "Epoch 23/30\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.4525 - acc: 0.8058\n",
            "Epoch 24/30\n",
            "891/891 [==============================] - 0s 435us/step - loss: 0.4313 - acc: 0.8036\n",
            "Epoch 25/30\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4422 - acc: 0.8126\n",
            "Epoch 26/30\n",
            "891/891 [==============================] - 0s 465us/step - loss: 0.4308 - acc: 0.8171\n",
            "Epoch 27/30\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4296 - acc: 0.8058\n",
            "Epoch 28/30\n",
            "891/891 [==============================] - 0s 448us/step - loss: 0.4182 - acc: 0.8148\n",
            "Epoch 29/30\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.4349 - acc: 0.8058\n",
            "Epoch 30/30\n",
            "891/891 [==============================] - 0s 450us/step - loss: 0.4224 - acc: 0.8058\n",
            "891/891 [==============================] - 0s 308us/step\n",
            "acc: 79.80%\n",
            "14.150184154510498\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}