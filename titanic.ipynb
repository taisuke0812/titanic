{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/taisuke0812/titanic/blob/master/titanic.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Rj9SBzz1rFod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5385
        },
        "outputId": "a729c9a0-87dc-4953-fad3-37dd5bf6d4e0"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "#train\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"male\",1)\n",
        "train[\"Sex\"] = train[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"S\",2)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"Q\",1)\n",
        "train[\"Embarked\"] = train[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "train = train.drop(\"Cabin\",axis = 1)\n",
        "train = train.drop(\"Name\",axis = 1)\n",
        "train = train.drop(\"Ticket\",axis = 1)\n",
        "train = train.drop(\"PassengerId\",axis = 1)\n",
        "train = train.fillna(train[\"Fare\"].mean())\n",
        "train = train.fillna(train[\"Age\"].mean())\n",
        "\n",
        "train_X = np.array(train.drop(\"Survived\",axis = 1))\n",
        "train_y = np.array(train[\"Survived\"])\n",
        "\n",
        "\n",
        "#test\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df = test[:]\n",
        "PassengerId = test[\"PassengerId\"][:]\n",
        "\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"male\",1)\n",
        "test[\"Sex\"] = test[\"Sex\"][:].replace(\"female\",0)\n",
        "\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"S\",2)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"Q\",1)\n",
        "test[\"Embarked\"] = test[\"Embarked\"][:].replace(\"C\",0)\n",
        "\n",
        "test = test.drop(\"Cabin\",axis = 1)\n",
        "test = test.drop(\"Name\",axis = 1)\n",
        "test = test.drop(\"Ticket\",axis = 1)\n",
        "test = test.drop(\"PassengerId\",axis=1)\n",
        "test = test.fillna(test[\"Fare\"].mean())\n",
        "test = test.fillna(test[\"Age\"].mean())\n",
        "\n",
        "test_X = test[:]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512,input_dim = 7,activation = \"relu\"))\n",
        "model.add(Dense(256,activation = \"relu\"))\n",
        "model.add(Dense(128,activation = \"relu\"))\n",
        "model.add(Dense(64,activation = \"sigmoid\"))\n",
        "model.add(Dense(32,activation = \"relu\"))\n",
        "model.add(Dense(16,activation = \"sigmoid\"))\n",
        "model.add(Dense(8,activation = \"relu\"))\n",
        "model.add(Dense(4,activation = \"sigmoid\"))\n",
        "model.add(Dense(2,activation = \"relu\"))\n",
        "model.add(Dense(1,activation = \"relu\"))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_X,train_y, nb_epoch=150, batch_size=20)\n",
        "\n",
        "\n",
        "scores = model.evaluate(train_X, train_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
        "predict = model.predict(test_X)\n",
        "predictions = np.round(np.array(predict))\n",
        "predictions = np.ravel(predictions)\n",
        "\n",
        "\n",
        "\n",
        "#print(predictions)\n",
        "\n",
        "#StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,'Survived': predictions })\n",
        "#StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)\n",
        "\n",
        "df[\"Survived\"] = predictions\n",
        "\n",
        "df[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "end_time = time.time() - start\n",
        "print(end_time)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.6648 - acc: 0.5892\n",
            "Epoch 2/150\n",
            "891/891 [==============================] - 0s 460us/step - loss: 0.6303 - acc: 0.6431\n",
            "Epoch 3/150\n",
            "891/891 [==============================] - 0s 452us/step - loss: 0.6122 - acc: 0.6891\n",
            "Epoch 4/150\n",
            "891/891 [==============================] - 0s 453us/step - loss: 0.6143 - acc: 0.6723\n",
            "Epoch 5/150\n",
            "891/891 [==============================] - 0s 454us/step - loss: 0.6079 - acc: 0.6835\n",
            "Epoch 6/150\n",
            "891/891 [==============================] - 0s 453us/step - loss: 0.6049 - acc: 0.6902\n",
            "Epoch 7/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.5878 - acc: 0.6857\n",
            "Epoch 8/150\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.5793 - acc: 0.6869\n",
            "Epoch 9/150\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.5775 - acc: 0.6902\n",
            "Epoch 10/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.5330 - acc: 0.7284\n",
            "Epoch 11/150\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.5487 - acc: 0.7273\n",
            "Epoch 12/150\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.5009 - acc: 0.7778\n",
            "Epoch 13/150\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.4831 - acc: 0.7733\n",
            "Epoch 14/150\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.5005 - acc: 0.7823\n",
            "Epoch 15/150\n",
            "891/891 [==============================] - 0s 468us/step - loss: 0.4681 - acc: 0.7946\n",
            "Epoch 16/150\n",
            "891/891 [==============================] - 0s 455us/step - loss: 0.4716 - acc: 0.7935\n",
            "Epoch 17/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4629 - acc: 0.7991\n",
            "Epoch 18/150\n",
            "891/891 [==============================] - 0s 440us/step - loss: 0.4562 - acc: 0.8047\n",
            "Epoch 19/150\n",
            "891/891 [==============================] - 0s 459us/step - loss: 0.4508 - acc: 0.8137\n",
            "Epoch 20/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.4660 - acc: 0.8002\n",
            "Epoch 21/150\n",
            "891/891 [==============================] - 0s 472us/step - loss: 0.4529 - acc: 0.8002\n",
            "Epoch 22/150\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.4520 - acc: 0.8070\n",
            "Epoch 23/150\n",
            "891/891 [==============================] - 0s 470us/step - loss: 0.4385 - acc: 0.8114\n",
            "Epoch 24/150\n",
            "891/891 [==============================] - 0s 462us/step - loss: 0.4425 - acc: 0.8126\n",
            "Epoch 25/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4346 - acc: 0.8025\n",
            "Epoch 26/150\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.4284 - acc: 0.8070\n",
            "Epoch 27/150\n",
            "891/891 [==============================] - 0s 466us/step - loss: 0.4436 - acc: 0.8238\n",
            "Epoch 28/150\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.5130 - acc: 0.7565\n",
            "Epoch 29/150\n",
            "891/891 [==============================] - 0s 461us/step - loss: 0.6125 - acc: 0.6700\n",
            "Epoch 30/150\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.4837 - acc: 0.7800\n",
            "Epoch 31/150\n",
            "891/891 [==============================] - 0s 472us/step - loss: 0.4935 - acc: 0.7710\n",
            "Epoch 32/150\n",
            "891/891 [==============================] - 0s 466us/step - loss: 0.4651 - acc: 0.8036\n",
            "Epoch 33/150\n",
            "891/891 [==============================] - 0s 468us/step - loss: 0.4472 - acc: 0.8137\n",
            "Epoch 34/150\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4419 - acc: 0.8148\n",
            "Epoch 35/150\n",
            "891/891 [==============================] - 0s 460us/step - loss: 0.4388 - acc: 0.8159\n",
            "Epoch 36/150\n",
            "891/891 [==============================] - 0s 469us/step - loss: 0.4611 - acc: 0.7957\n",
            "Epoch 37/150\n",
            "891/891 [==============================] - 0s 469us/step - loss: 0.4301 - acc: 0.8171\n",
            "Epoch 38/150\n",
            "891/891 [==============================] - 0s 458us/step - loss: 0.4488 - acc: 0.7980\n",
            "Epoch 39/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.4265 - acc: 0.8103\n",
            "Epoch 40/150\n",
            "891/891 [==============================] - 0s 447us/step - loss: 0.4259 - acc: 0.8215\n",
            "Epoch 41/150\n",
            "891/891 [==============================] - 0s 429us/step - loss: 0.4489 - acc: 0.8328\n",
            "Epoch 42/150\n",
            "891/891 [==============================] - 0s 421us/step - loss: 0.4234 - acc: 0.8238\n",
            "Epoch 43/150\n",
            "891/891 [==============================] - 0s 439us/step - loss: 0.4223 - acc: 0.8227\n",
            "Epoch 44/150\n",
            "891/891 [==============================] - 0s 457us/step - loss: 0.4099 - acc: 0.8249\n",
            "Epoch 45/150\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.4198 - acc: 0.8215\n",
            "Epoch 46/150\n",
            "891/891 [==============================] - 0s 465us/step - loss: 0.4313 - acc: 0.8092\n",
            "Epoch 47/150\n",
            "891/891 [==============================] - 0s 450us/step - loss: 0.4143 - acc: 0.8215\n",
            "Epoch 48/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.4095 - acc: 0.8272\n",
            "Epoch 49/150\n",
            "891/891 [==============================] - 0s 440us/step - loss: 0.4067 - acc: 0.8204\n",
            "Epoch 50/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4037 - acc: 0.8215\n",
            "Epoch 51/150\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.4200 - acc: 0.8193\n",
            "Epoch 52/150\n",
            "891/891 [==============================] - 0s 466us/step - loss: 0.4119 - acc: 0.8249\n",
            "Epoch 53/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4252 - acc: 0.8171\n",
            "Epoch 54/150\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.4360 - acc: 0.8316\n",
            "Epoch 55/150\n",
            "891/891 [==============================] - 0s 436us/step - loss: 0.4221 - acc: 0.8204\n",
            "Epoch 56/150\n",
            "891/891 [==============================] - 0s 443us/step - loss: 0.4249 - acc: 0.8249\n",
            "Epoch 57/150\n",
            "891/891 [==============================] - 0s 453us/step - loss: 0.3986 - acc: 0.8350\n",
            "Epoch 58/150\n",
            "891/891 [==============================] - 0s 450us/step - loss: 0.4018 - acc: 0.8283\n",
            "Epoch 59/150\n",
            "891/891 [==============================] - 0s 469us/step - loss: 0.3907 - acc: 0.8316\n",
            "Epoch 60/150\n",
            "891/891 [==============================] - 0s 453us/step - loss: 0.4016 - acc: 0.8249\n",
            "Epoch 61/150\n",
            "891/891 [==============================] - 0s 460us/step - loss: 0.4256 - acc: 0.8215\n",
            "Epoch 62/150\n",
            "891/891 [==============================] - 0s 452us/step - loss: 0.4034 - acc: 0.8249\n",
            "Epoch 63/150\n",
            "891/891 [==============================] - 0s 462us/step - loss: 0.4133 - acc: 0.8384\n",
            "Epoch 64/150\n",
            "891/891 [==============================] - 0s 458us/step - loss: 0.4010 - acc: 0.8316\n",
            "Epoch 65/150\n",
            "891/891 [==============================] - 0s 473us/step - loss: 0.3907 - acc: 0.8395\n",
            "Epoch 66/150\n",
            "891/891 [==============================] - 0s 467us/step - loss: 0.3919 - acc: 0.8316\n",
            "Epoch 67/150\n",
            "891/891 [==============================] - 0s 465us/step - loss: 0.4010 - acc: 0.8227\n",
            "Epoch 68/150\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4093 - acc: 0.8193\n",
            "Epoch 69/150\n",
            "891/891 [==============================] - 0s 467us/step - loss: 0.3951 - acc: 0.8350\n",
            "Epoch 70/150\n",
            "891/891 [==============================] - 0s 475us/step - loss: 0.3854 - acc: 0.8384\n",
            "Epoch 71/150\n",
            "891/891 [==============================] - 0s 455us/step - loss: 0.3903 - acc: 0.8260\n",
            "Epoch 72/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.3991 - acc: 0.8384\n",
            "Epoch 73/150\n",
            "891/891 [==============================] - 0s 447us/step - loss: 0.4111 - acc: 0.8361\n",
            "Epoch 74/150\n",
            "891/891 [==============================] - 0s 443us/step - loss: 0.4043 - acc: 0.8316\n",
            "Epoch 75/150\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.3894 - acc: 0.8305\n",
            "Epoch 76/150\n",
            "891/891 [==============================] - 0s 434us/step - loss: 0.3900 - acc: 0.8373\n",
            "Epoch 77/150\n",
            "891/891 [==============================] - 0s 443us/step - loss: 0.3807 - acc: 0.8373\n",
            "Epoch 78/150\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.3832 - acc: 0.8384\n",
            "Epoch 79/150\n",
            "891/891 [==============================] - 0s 443us/step - loss: 0.4072 - acc: 0.8305\n",
            "Epoch 80/150\n",
            "891/891 [==============================] - 0s 447us/step - loss: 0.3895 - acc: 0.8305\n",
            "Epoch 81/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.3869 - acc: 0.8339\n",
            "Epoch 82/150\n",
            "891/891 [==============================] - 0s 455us/step - loss: 0.3886 - acc: 0.8260\n",
            "Epoch 83/150\n",
            "891/891 [==============================] - 0s 462us/step - loss: 0.3827 - acc: 0.8328\n",
            "Epoch 84/150\n",
            "891/891 [==============================] - 0s 465us/step - loss: 0.3773 - acc: 0.8384\n",
            "Epoch 85/150\n",
            "891/891 [==============================] - 0s 482us/step - loss: 0.5824 - acc: 0.7284\n",
            "Epoch 86/150\n",
            "891/891 [==============================] - 0s 468us/step - loss: 0.5265 - acc: 0.7576\n",
            "Epoch 87/150\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.4992 - acc: 0.7587\n",
            "Epoch 88/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.4693 - acc: 0.8002\n",
            "Epoch 89/150\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.4586 - acc: 0.8126\n",
            "Epoch 90/150\n",
            "891/891 [==============================] - 0s 462us/step - loss: 0.4496 - acc: 0.8025\n",
            "Epoch 91/150\n",
            "891/891 [==============================] - 0s 430us/step - loss: 0.4692 - acc: 0.7924\n",
            "Epoch 92/150\n",
            "891/891 [==============================] - 0s 462us/step - loss: 0.4492 - acc: 0.8103\n",
            "Epoch 93/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4423 - acc: 0.8137\n",
            "Epoch 94/150\n",
            "891/891 [==============================] - 0s 452us/step - loss: 0.4424 - acc: 0.7991\n",
            "Epoch 95/150\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.4321 - acc: 0.8159\n",
            "Epoch 96/150\n",
            "891/891 [==============================] - 0s 450us/step - loss: 0.4305 - acc: 0.8182\n",
            "Epoch 97/150\n",
            "891/891 [==============================] - 0s 482us/step - loss: 0.4282 - acc: 0.8148\n",
            "Epoch 98/150\n",
            "891/891 [==============================] - 0s 473us/step - loss: 0.4186 - acc: 0.8148\n",
            "Epoch 99/150\n",
            "891/891 [==============================] - 0s 466us/step - loss: 0.4072 - acc: 0.8283\n",
            "Epoch 100/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4084 - acc: 0.8272\n",
            "Epoch 101/150\n",
            "891/891 [==============================] - 0s 470us/step - loss: 0.4135 - acc: 0.8215\n",
            "Epoch 102/150\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4119 - acc: 0.8137\n",
            "Epoch 103/150\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.4010 - acc: 0.8294\n",
            "Epoch 104/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4094 - acc: 0.8182\n",
            "Epoch 105/150\n",
            "891/891 [==============================] - 0s 473us/step - loss: 0.4034 - acc: 0.8238\n",
            "Epoch 106/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4414 - acc: 0.8036\n",
            "Epoch 107/150\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.4129 - acc: 0.8171\n",
            "Epoch 108/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4061 - acc: 0.8272\n",
            "Epoch 109/150\n",
            "891/891 [==============================] - 0s 468us/step - loss: 0.4336 - acc: 0.8126\n",
            "Epoch 110/150\n",
            "891/891 [==============================] - 0s 454us/step - loss: 0.3896 - acc: 0.8260\n",
            "Epoch 111/150\n",
            "891/891 [==============================] - 0s 460us/step - loss: 0.4079 - acc: 0.8272\n",
            "Epoch 112/150\n",
            "891/891 [==============================] - 0s 455us/step - loss: 0.4235 - acc: 0.8249\n",
            "Epoch 113/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.4418 - acc: 0.8294\n",
            "Epoch 114/150\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.5106 - acc: 0.7722\n",
            "Epoch 115/150\n",
            "891/891 [==============================] - 0s 467us/step - loss: 0.4636 - acc: 0.7722\n",
            "Epoch 116/150\n",
            "891/891 [==============================] - 0s 464us/step - loss: 0.4157 - acc: 0.8159\n",
            "Epoch 117/150\n",
            "891/891 [==============================] - 0s 455us/step - loss: 0.4048 - acc: 0.8227\n",
            "Epoch 118/150\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.4019 - acc: 0.8283\n",
            "Epoch 119/150\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.3895 - acc: 0.8272\n",
            "Epoch 120/150\n",
            "891/891 [==============================] - 0s 477us/step - loss: 0.4087 - acc: 0.8272\n",
            "Epoch 121/150\n",
            "891/891 [==============================] - 0s 477us/step - loss: 0.3906 - acc: 0.8361\n",
            "Epoch 122/150\n",
            "891/891 [==============================] - 0s 466us/step - loss: 0.3829 - acc: 0.8283\n",
            "Epoch 123/150\n",
            "891/891 [==============================] - 0s 476us/step - loss: 0.3872 - acc: 0.8350\n",
            "Epoch 124/150\n",
            "891/891 [==============================] - 0s 457us/step - loss: 0.3953 - acc: 0.8316\n",
            "Epoch 125/150\n",
            "891/891 [==============================] - 0s 469us/step - loss: 0.3981 - acc: 0.8316\n",
            "Epoch 126/150\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.3871 - acc: 0.8373\n",
            "Epoch 127/150\n",
            "891/891 [==============================] - 0s 460us/step - loss: 0.3838 - acc: 0.8361\n",
            "Epoch 128/150\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.3840 - acc: 0.8406\n",
            "Epoch 129/150\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.3872 - acc: 0.8361\n",
            "Epoch 130/150\n",
            "891/891 [==============================] - 0s 461us/step - loss: 0.3978 - acc: 0.8418\n",
            "Epoch 131/150\n",
            "891/891 [==============================] - 0s 472us/step - loss: 0.3893 - acc: 0.8418\n",
            "Epoch 132/150\n",
            "891/891 [==============================] - 0s 482us/step - loss: 0.3890 - acc: 0.8361\n",
            "Epoch 133/150\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.4110 - acc: 0.8126\n",
            "Epoch 134/150\n",
            "891/891 [==============================] - 0s 470us/step - loss: 0.5193 - acc: 0.7116\n",
            "Epoch 135/150\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.4572 - acc: 0.7868\n",
            "Epoch 136/150\n",
            "891/891 [==============================] - 0s 448us/step - loss: 0.4406 - acc: 0.7946\n",
            "Epoch 137/150\n",
            "891/891 [==============================] - 0s 458us/step - loss: 0.4202 - acc: 0.8148\n",
            "Epoch 138/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4075 - acc: 0.8092\n",
            "Epoch 139/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.4062 - acc: 0.8070\n",
            "Epoch 140/150\n",
            "891/891 [==============================] - 0s 452us/step - loss: 0.3942 - acc: 0.8204\n",
            "Epoch 141/150\n",
            "891/891 [==============================] - 0s 456us/step - loss: 0.3871 - acc: 0.8350\n",
            "Epoch 142/150\n",
            "891/891 [==============================] - 0s 431us/step - loss: 0.3897 - acc: 0.8316\n",
            "Epoch 143/150\n",
            "891/891 [==============================] - 0s 451us/step - loss: 0.3880 - acc: 0.8395\n",
            "Epoch 144/150\n",
            "891/891 [==============================] - 0s 433us/step - loss: 0.3886 - acc: 0.8406\n",
            "Epoch 145/150\n",
            "891/891 [==============================] - 0s 431us/step - loss: 0.3827 - acc: 0.8384\n",
            "Epoch 146/150\n",
            "891/891 [==============================] - 0s 434us/step - loss: 0.3834 - acc: 0.8384\n",
            "Epoch 147/150\n",
            "891/891 [==============================] - 0s 445us/step - loss: 0.3773 - acc: 0.8462\n",
            "Epoch 148/150\n",
            "891/891 [==============================] - 0s 449us/step - loss: 0.3757 - acc: 0.8462\n",
            "Epoch 149/150\n",
            "891/891 [==============================] - 0s 427us/step - loss: 0.3942 - acc: 0.8418\n",
            "Epoch 150/150\n",
            "891/891 [==============================] - 0s 439us/step - loss: 0.4321 - acc: 0.8429\n",
            "891/891 [==============================] - 2s 2ms/step\n",
            "acc: 83.95%\n",
            "70.59412360191345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6KOVij9mu_r1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "psXfWz4liC54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}